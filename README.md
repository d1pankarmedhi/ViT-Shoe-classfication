<div align="center">

# ğŸ‘Ÿ ViT Shoe Classifier: Brand Recognition with Vision Transformer 

ViT paper implementation in PyTorch for classification of shoe brands.

![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
</div>

## ğŸš€ Overview

This project implements a Vision Transformer (ViT) in PyTorch to classify shoe images into three popular brands: **Adidas**, **Converse**, and **Nike**. The goal is to accurately identify the brand of a shoe from an input image.

## ğŸ¯ Final Results

Check out the training progress and performance!

<div align="center">
    <div>
        <img src="https://github.com/d1pankarmedhi/ViT-vision-transformer/assets/136924835/4fc00ff4-958d-47c0-bd07-443ddf024fb4" width=600 alt="loss and accuracy"> <img src="https://github.com/d1pankarmedhi/ViT-vision-transformer/assets/136924835/bff5e439-9655-4831-b3e5-19d6c0dcb52a" width=300 alt="Image 3">
    </div>
</div>

## ğŸ‹ï¸ Model Architecture

This project utilizes a **Vision Transformer (ViT-Base)** architecture, boasting approximately **86 million parameters**.


<div align="center">
<img src="https://github.com/d1pankarmedhi/ViT-vision-transformer/assets/136924835/21dde5ed-e9db-46de-9ec5-101854ed24d9" width=700>
</div>

### ğŸ’¡ Fine tuning

Pre-trained weights from the **[ViT-B_16](https://pytorch.org/vision/main/models/generated/torchvision.models.vit_b_16.html#vit-b-16)  model in `torchvision`** were leveraged to significantly improve model performance and training efficiency by fine-tuning the model on shoe dataset.

### â­ Connect
Connect with me to discuss more on ViT and Vision Language Models. 
